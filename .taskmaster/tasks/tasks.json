{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Setup Project Infrastructure and Database Schema",
        "description": "Initialize the foundational infrastructure including PostgreSQL database schema, Redis setup, and core project structure for the Rust backend services.",
        "details": "Create PostgreSQL 17+ database with tables for User {id, email, provider, roles, settings}, MediaItem {id, type, metadata, s3Key, status}, and Session {token, userId, expiresAt}. Set up Redis 6+ for caching and session storage. Initialize Rust workspace with Tokio async runtime (Rust edition 2024). Configure database migrations using sqlx or diesel. Set up connection pooling and basic error handling.",
        "testStrategy": "Unit tests for database connection, schema validation, and basic CRUD operations. Integration tests for Redis connectivity and session storage.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Initialize Rust Workspace and Project Structure",
            "description": "Set up the core Rust monorepo workspace using Cargo, configured with the Tokio async runtime and Rust 2024 edition.",
            "dependencies": [],
            "details": "Create a new Cargo workspace. Configure the root `Cargo.toml` to specify the 2024 edition. Add `tokio` as a core dependency with 'full' features. Establish a basic directory structure for future microservices (e.g., `services/`, `libs/`).\n<info added on 2025-07-31T14:22:45.787Z>\nSubtask 1.1 has been successfully completed. The Rust workspace is now properly initialized with all required dependencies and directory structure in place. Key accomplishments include workspace configuration with resolver = \"2\", Rust 2024 edition setup, comprehensive dependency management through workspace.dependencies, and creation of a valid workspace structure with services/ and libs/ directories plus an initial common library crate. The project has been verified to compile successfully and is ready for database provisioning and schema definition.\n</info added on 2025-07-31T14:22:45.787Z>",
            "status": "done",
            "testStrategy": "Verify the project compiles successfully using `cargo check` and `cargo build`."
          },
          {
            "id": 2,
            "title": "Provision PostgreSQL and Define Schema with Migrations",
            "description": "Set up a PostgreSQL 17+ instance and use `sqlx-cli` to define and apply the initial database schema for User, MediaItem, and Session tables.",
            "dependencies": [],
            "details": "Provision a PostgreSQL 17+ server (e.g., using Docker). Install `sqlx-cli`. Initialize migrations and create the first migration file defining the `User` {id, email, provider, roles, settings}, `MediaItem` {id, type, metadata, s3Key, status}, and `Session` {token, userId, expiresAt} tables with appropriate data types (e.g., UUID, TEXT, JSONB, TIMESTAMPTZ).\n<info added on 2025-07-31T14:30:39.885Z>\nCOMPLETED: Successfully provisioned PostgreSQL 17 and Redis 7 services using Docker Compose with health checks. Installed sqlx-cli v0.8.6 and initialized comprehensive database schema with Users, MediaItems, and Sessions tables including proper UUID support, JSONB fields, foreign key constraints, performance indexes, and automatic timestamp triggers. All migrations applied successfully and database is ready for connection pooling implementation.\n</info added on 2025-07-31T14:30:39.885Z>",
            "status": "done",
            "testStrategy": "Apply the migration using `sqlx migrate run`. Manually verify the table structures and constraints using a SQL client."
          },
          {
            "id": 3,
            "title": "Implement PostgreSQL Connection Pooling in Rust",
            "description": "Integrate the `sqlx` crate into the Rust project to establish a connection pool to the PostgreSQL database and implement basic data access logic.",
            "dependencies": [
              "1.1",
              "1.2"
            ],
            "details": "Add `sqlx` with `postgres` and `runtime-tokio-rustls` features to project dependencies. Create a database module to manage the `PgPool` instance, configured via environment variables. Implement a basic health check function to verify database connectivity. Define custom error types for database operations.\n<info added on 2025-08-01T09:05:29.444Z>\nImplementation completed successfully. The database module now includes:\n\n- DatabaseConfig struct with environment variable configuration (DATABASE_URL, MAX_CONNECTIONS, MIN_CONNECTIONS, CONNECTION_TIMEOUT)\n- Connection pool initialization with configurable parameters and proper error handling\n- Health check endpoint that verifies database connectivity and returns connection status\n- Custom error types using thiserror for comprehensive database operation error handling\n- Unit tests covering configuration parsing, pool initialization, and health check functionality\n\nThe module provides a robust foundation for database operations with proper connection management, configuration flexibility, and comprehensive error handling throughout the application.\n</info added on 2025-08-01T09:05:29.444Z>",
            "status": "done",
            "testStrategy": "Write a unit test that successfully acquires a connection from the pool and performs a simple query (e.g., `SELECT 1`). Test connection failure scenarios."
          },
          {
            "id": 4,
            "title": "Provision Redis and Implement Rust Client",
            "description": "Set up a Redis 6+ instance and integrate a Redis client into the Rust application for future caching and session storage.",
            "dependencies": [
              "1.1"
            ],
            "details": "Provision a Redis 6+ server (e.g., using Docker). Add the `redis` crate with the `tokio-comp` feature to the project. Create a cache module to manage the Redis connection, configured via environment variables. Implement basic `get` and `set` wrapper functions.",
            "status": "done",
            "testStrategy": "Write an integration test to connect to Redis, set a key-value pair with a TTL, retrieve it, and verify it is deleted after the TTL expires."
          },
          {
            "id": 5,
            "title": "Create Initial Infrastructure Integration Tests",
            "description": "Develop a suite of integration tests to validate that the Rust application can connect to both PostgreSQL and Redis, and that the database schema is correctly set up.",
            "dependencies": [
              "1.3",
              "1.4"
            ],
            "details": "Create an integration test that initializes both the PostgreSQL connection pool and the Redis client. The test should perform a simple write/read operation against a test table in the database. It should also perform a SET/GET operation in Redis to confirm both services are reachable and operational from the application.",
            "status": "done",
            "testStrategy": "Run the integration test suite using `cargo test`. Success is defined by all tests passing, confirming the foundational infrastructure is correctly configured and accessible."
          }
        ]
      },
      {
        "id": 2,
        "title": "Implement Authentication Service with OAuth2 and JWT",
        "description": "Build the authentication microservice supporting OAuth2 providers (Google, Apple) and basic auth with JWT token management.",
        "details": "Implement Rust-based auth service using oauth2 crate for Google/Apple integration and basic username/password auth. Generate and validate JWTs using jsonwebtoken crate. Store sessions in Redis with expiration. Create RESTful endpoints: POST /auth/login, POST /auth/oauth/callback, POST /auth/refresh, DELETE /auth/logout. Implement RBAC with user roles stored in PostgreSQL.",
        "testStrategy": "Unit tests for JWT generation/validation, OAuth2 flow simulation, and session management. Integration tests with mock OAuth providers and Redis session storage.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "in-progress",
        "subtasks": [
          {
            "id": 1,
            "title": "Set up Rust authentication service foundation with database models",
            "description": "Create the basic Rust project structure for the authentication service and implement PostgreSQL database models for users, roles, and sessions with RBAC support.",
            "dependencies": [],
            "details": "Initialize new Rust project with Cargo.toml dependencies (tokio, axum, sqlx, serde). Create database schema with users table (id, username, email, password_hash, created_at), roles table (id, name, permissions), user_roles junction table, and sessions table (id, user_id, token_hash, expires_at). Implement SQLx models and database connection setup with connection pooling. Set up database migrations using sqlx-cli.",
            "status": "done",
            "testStrategy": "Unit tests for database model creation, connection establishment, and basic CRUD operations on user and role entities."
          },
          {
            "id": 2,
            "title": "Implement JWT token generation and validation system",
            "description": "Build the JWT token management system using jsonwebtoken crate for creating, validating, and refreshing access and refresh tokens.",
            "dependencies": [
              "2.1"
            ],
            "details": "Implement JWT service using jsonwebtoken crate with RS256 algorithm. Create functions for generating access tokens (15min expiry) and refresh tokens (7 days expiry). Include user ID, roles, and permissions in JWT claims. Implement token validation middleware for protected routes. Add token blacklisting mechanism using Redis for logout functionality. Create refresh token rotation for enhanced security.",
            "status": "done",
            "testStrategy": "Unit tests for token generation with various payloads, token validation with expired/invalid tokens, and refresh token rotation scenarios."
          },
          {
            "id": 3,
            "title": "Implement basic username/password authentication endpoints",
            "description": "Create RESTful endpoints for user registration, login, and logout with password hashing and session management.",
            "dependencies": [
              "2.1",
              "2.2"
            ],
            "details": "Implement POST /auth/register endpoint with password hashing using argon2. Create POST /auth/login endpoint that validates credentials, generates JWT tokens, and stores session in Redis. Implement DELETE /auth/logout endpoint that invalidates tokens and removes Redis session. Add input validation using serde and custom validators. Implement rate limiting for login attempts to prevent brute force attacks.",
            "status": "done",
            "testStrategy": "Integration tests for registration with various input scenarios, login with valid/invalid credentials, and logout token invalidation. Load testing for rate limiting effectiveness."
          },
          {
            "id": 4,
            "title": "Integrate OAuth2 providers (Google and Apple) with callback handling",
            "description": "Implement OAuth2 authentication flow using oauth2 crate for Google and Apple sign-in with proper callback handling and user account linking.",
            "dependencies": [
              "2.1",
              "2.2"
            ],
            "details": "Set up OAuth2 clients for Google and Apple using oauth2 crate. Implement authorization URL generation with proper scopes and PKCE for security. Create POST /auth/oauth/callback endpoint to handle authorization codes, exchange for access tokens, and retrieve user profile information. Implement user account creation or linking logic for OAuth users. Store OAuth provider information in user profiles and handle email verification status from providers.",
            "status": "done",
            "testStrategy": "Integration tests with mock OAuth providers simulating successful and failed authentication flows. Unit tests for user profile creation and account linking scenarios."
          },
          {
            "id": 5,
            "title": "Implement Redis session management and token refresh endpoint",
            "description": "Set up Redis integration for session storage with expiration and implement the token refresh endpoint for seamless authentication experience.",
            "dependencies": [
              "2.2",
              "2.3"
            ],
            "details": "Integrate Redis using redis crate with connection pooling. Implement session storage with automatic expiration matching token lifetimes. Create POST /auth/refresh endpoint that validates refresh tokens, generates new access tokens, and updates Redis sessions. Implement session cleanup for expired tokens and user logout across multiple devices. Add Redis health checks and fallback mechanisms for service reliability.",
            "status": "done",
            "testStrategy": "Unit tests for Redis session operations (create, read, update, delete) and TTL functionality. Integration tests for token refresh flow and session cleanup. Performance tests for concurrent session management."
          }
        ]
      },
      {
        "id": 3,
        "title": "Develop S3 Integration and Media Ingestion Service",
        "description": "Create the media ingestion service that scans S3 buckets, extracts metadata using FFprobe, and stores information in PostgreSQL.",
        "details": "Build Rust service using aws-sdk-s3 for S3 operations and ffmpeg-next crate for metadata extraction. Implement periodic scanning of S3 buckets/folders, extract metadata (duration, resolution, codec, etc.) using ffprobe, generate thumbnails and store in separate S3 bucket. Update PostgreSQL with media metadata and create search indices. Handle various media formats (movies, shows, music, photos).",
        "testStrategy": "Unit tests for S3 operations, metadata extraction, and database updates. Integration tests with mock S3 buckets and sample media files.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "in-progress",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement S3 Bucket Polling and File Discovery",
            "description": "Create a service component to periodically scan specified S3 buckets for new or updated media files using the aws-sdk-s3 crate.",
            "dependencies": [],
            "details": "Develop a recurring job using a scheduler (e.g., tokio-cron-scheduler) to list objects in the target S3 bucket. The service must track processed files, possibly by checking S3 object etags or last modified dates against a database record, to avoid reprocessing existing media.",
            "status": "done",
            "testStrategy": "Unit test the S3 listing and file filtering logic. Integration test against a mock S3 service like LocalStack to verify the discovery of new, updated, and unchanged files."
          },
          {
            "id": 2,
            "title": "Extract Media Metadata using FFprobe",
            "description": "For each discovered media file, integrate the ffmpeg-next crate to execute ffprobe and parse its JSON output to extract metadata.",
            "dependencies": [
              "3.1"
            ],
            "details": "Implement a function that takes an S3 object key, downloads the file temporarily, and runs ffprobe. Extract key metadata including duration, resolution, codecs (video/audio), container format, and bitrate. Structure the extracted data into a Rust struct. Implement error handling for corrupted or unsupported files.",
            "status": "done",
            "testStrategy": "Unit test the ffprobe output parser with sample JSON outputs for various media types (movies, music, photos). Integration test with a set of sample media files to ensure the end-to-end extraction process works correctly."
          },
          {
            "id": 3,
            "title": "Generate Thumbnails with FFmpeg and Upload to S3",
            "description": "For video files, use FFmpeg to generate a thumbnail image and upload it to a separate, designated S3 bucket for thumbnails.",
            "dependencies": [
              "3.1"
            ],
            "details": "Use the ffmpeg-next crate to invoke an ffmpeg command that extracts a single frame from a video (e.g., at the 10% mark). After generating the thumbnail (e.g., as a JPEG), use the aws-sdk-s3 crate to upload it to the configured thumbnail bucket. The key for the thumbnail should be predictably derived from the original media's key.",
            "status": "done",
            "testStrategy": "Unit test the FFmpeg command generation logic. Integration test by processing a sample video file, verifying the thumbnail is created locally, and then confirming its successful upload to a mock S3 bucket."
          },
          {
            "id": 4,
            "title": "Define PostgreSQL Schema and Persist Metadata",
            "description": "Design the PostgreSQL database schema for storing media information and implement the logic to write the extracted metadata and thumbnail URLs.",
            "dependencies": [
              "3.2",
              "3.3"
            ],
            "details": "Using a crate like `sqlx` or `diesel`, define the database schema with tables for different media types (e.g., `media_items`). The schema should accommodate all metadata from subtask 2 and the S3 URL for the thumbnail from subtask 3. Implement transactional database writes to ensure data consistency when creating or updating a media record.",
            "status": "done",
            "testStrategy": "Write unit tests for the data access layer using a mocked database connection. Run integration tests against a test PostgreSQL database to verify schema migrations and the correctness of INSERT/UPDATE operations."
          },
          {
            "id": 5,
            "title": "Implement Search Indices and Finalize Ingestion Pipeline",
            "description": "Create necessary search indices in PostgreSQL to optimize queries and wire together all components into a complete, error-handled ingestion pipeline.",
            "dependencies": [
              "3.4"
            ],
            "details": "Add PostgreSQL indices on frequently queried columns like title, media type, and genre to improve search performance for the client application. Combine the S3 polling, metadata extraction, thumbnail generation, and database persistence steps into a single, cohesive workflow. Implement robust error handling and logging for each stage of the pipeline, including a mechanism for retrying failed jobs.\n<info added on 2025-08-01T13:14:28.336Z>\nImplementation Plan for 'Implement Search Indices and Finalize Ingestion Pipeline':\n\n1. **Database Indices:**\n   - The migration '20250801131000_add_search_indices.sql' creates indices on (type, status), (user_id, status), created_at (DESC), and a GIN index on the metadata JSONB column.\n   - There is no dedicated index for 'title' or 'genre'. The migration suggests (in comments) adding a generated column for title and indexing it. For optimal search performance, consider extracting 'title' and 'genre' from metadata into dedicated columns and indexing them in a future migration.\n\n2. **Pipeline Finalization:**\n   - Ensure the S3 polling, metadata extraction, thumbnail generation, and database persistence components are fully integrated into a single workflow (see s3_poller.rs, metadata_extractor.rs, thumbnail_generator.rs, database.rs).\n   - Add robust error handling and logging at each stage. Use structured logs for traceability.\n   - Implement a retry mechanism for failed jobs (e.g., using exponential backoff or a job queue).\n   - Ensure all errors are surfaced and do not silently fail.\n\n3. **Testing:**\n   - Use EXPLAIN ANALYZE on common queries (by title, type, genre) to verify index effectiveness.\n   - Conduct an end-to-end integration test: add a file to S3, verify the pipeline creates the correct DB entry, thumbnail, and logs.\n\n4. **Next Steps:**\n   - If not already done, implement the commented-out title column/index migration.\n   - Review and refactor the pipeline orchestration code for error handling and retries.\n   - Add or update tests as described above.\n\nThis plan is based on the current codebase and migration files as of 2025-08-01.\n</info added on 2025-08-01T13:14:28.336Z>",
            "status": "done",
            "testStrategy": "Verify index effectiveness using `EXPLAIN ANALYZE` on common query patterns. Conduct an end-to-end integration test where a file is added to the S3 bucket and the system is verified to have created the correct database entry, thumbnail, and logs."
          }
        ]
      },
      {
        "id": 4,
        "title": "Build Core REST API Endpoints",
        "description": "Implement RESTful API endpoints for media CRUD operations, user management, and session handling with proper authentication middleware.",
        "details": "Create Rust web server using axum or warp framework. Implement endpoints: GET/POST /users, GET /media (with filtering/search), GET /media/:id, POST /media/refresh, GET/DELETE /sessions. Add JWT authentication middleware for protected routes. Implement pagination, sorting, and filtering for media queries. Add request/response validation using serde and proper error handling with structured JSON responses.",
        "testStrategy": "Unit tests for each endpoint with mock authentication. Integration tests for full request/response cycles. API contract testing with OpenAPI specification.",
        "priority": "high",
        "dependencies": [
          2,
          3
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Initialize React Native Expo Client Application",
        "description": "Set up the React Native Expo monorepo targeting web, iOS/Android, and TV platforms with basic authentication flow and navigation.",
        "details": "Initialize Expo SDK (latest stable) with React 18 support. Configure monorepo structure for web, mobile, and TV targets. Implement authentication screens (login, OAuth callback handling) using expo-auth-session. Set up navigation using @react-navigation/native with stack and tab navigators. Create basic UI components with dark theme only. Configure platform-specific adaptations for touch and remote control inputs.",
        "testStrategy": "Unit tests for authentication flow components. E2E tests using Detox for mobile platforms. Manual testing on web, iOS simulator, and Android emulator.",
        "priority": "medium",
        "dependencies": [
          2
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Implement Redis Caching Layer for Performance",
        "description": "Integrate Redis caching for metadata queries, session management, and frequently accessed data to improve response times.",
        "details": "Implement Redis integration using redis-rs crate in Rust backend. Cache frequently accessed metadata queries with appropriate TTL values. Implement cache-aside pattern for media metadata, user sessions, and search results. Add cache invalidation strategies for media updates. Create Redis connection pooling and error handling for cache misses.",
        "testStrategy": "Unit tests for cache operations (get, set, delete, TTL). Performance tests comparing cached vs non-cached response times. Integration tests for cache invalidation scenarios.",
        "priority": "medium",
        "dependencies": [
          1,
          4
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Build Media Library UI and Basic Playback",
        "description": "Create the media library interface with browsing, searching, and basic HLS playback functionality in the React Native Expo client.",
        "details": "Implement media library screens with grid/list views for movies, shows, music, and photos. Add search and filtering capabilities by genre, title, and watch status. Integrate with backend API for media data fetching. Implement HLS video playback using expo-av with adaptive streaming. Add basic media controls (play, pause, seek, volume). Create responsive layouts for different screen sizes and orientations.",
        "testStrategy": "Unit tests for media library components and search functionality. Integration tests for API data fetching. Manual testing of playback across different devices and network conditions.",
        "priority": "medium",
        "dependencies": [
          4,
          5
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Develop FFmpeg Transcoding Service",
        "description": "Build the on-the-fly transcoding service using FFmpeg with hardware acceleration support for adaptive streaming.",
        "details": "Create Rust microservice using ffmpeg-next crate for transcoding operations. Implement client capability detection and adaptive bitrate streaming (HLS/DASH). Add hardware acceleration support (NVENC, QuickSync, VAAPI) when available. Create transcoding job queue with Redis for managing concurrent operations. Generate HLS segments and playlists dynamically. Implement pre-signed URL generation for S3 direct streaming when transcoding isn't needed.",
        "testStrategy": "Unit tests for transcoding logic and job queue management. Performance tests for transcoding speed and quality. Integration tests with various media formats and client capabilities.",
        "priority": "medium",
        "dependencies": [
          3,
          6
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Add WebSocket Support for Real-time Updates",
        "description": "Implement WebSocket connections for real-time library updates, transcoding progress, and live notifications.",
        "details": "Add WebSocket support to Rust backend using tokio-tungstenite. Implement real-time notifications for library changes, transcoding progress, and user activities. Create WebSocket authentication using JWT tokens. Add connection management with automatic reconnection in the client. Implement message queuing and delivery guarantees for critical updates.",
        "testStrategy": "Unit tests for WebSocket message handling and authentication. Integration tests for real-time update delivery. Load testing for concurrent WebSocket connections.",
        "priority": "low",
        "dependencies": [
          4,
          7
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Implement Offline Download and Advanced UI Features",
        "description": "Add offline download capabilities, advanced search, accessibility features, and UI refinements including themes and responsive design.",
        "details": "Implement offline download manager in React Native using expo-file-system for local storage. Add download progress tracking and queue management. Enhance search with advanced filters, sorting options, and search history. Implement accessibility features including screen reader support, keyboard navigation, and caption support. Add responsive design optimizations for TV remote control navigation and touch interfaces.",
        "testStrategy": "Unit tests for download manager and search functionality. Accessibility testing with screen readers. Manual testing on TV platforms and various device sizes.",
        "priority": "low",
        "dependencies": [
          7,
          8
        ],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-07-31T14:03:14.798Z",
      "updated": "2025-08-01T13:19:33.835Z",
      "description": "Tasks for master context"
    }
  }
}